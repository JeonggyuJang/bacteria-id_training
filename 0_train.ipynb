{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "The first step is to load the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, localtime, strftime\n",
    "t00 = time()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1000) (60000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = './data/X_reference.npy'\n",
    "y_train = './data/y_reference.npy'\n",
    "X = np.load(X_train)\n",
    "y = np.load(y_train)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters\n",
    "layers = 6\n",
    "hidden_size = 100\n",
    "block_size = 2\n",
    "hidden_sizes = [hidden_size] * layers\n",
    "num_blocks = [block_size] * layers\n",
    "input_dim = 1000\n",
    "in_channels = 64\n",
    "n_classes = 30\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ResNet(hidden_sizes, num_blocks, input_dim=input_dim,\n",
    "                in_channels=in_channels, n_classes=n_classes)\n",
    "if cuda: cnn.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import spectral_dataloader\n",
    "from training import run_epoch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/val split\n",
    "We split the training dataset into train and validation sets. We randomly sample 10% of the dataset to use as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 0.1\n",
    "n_val = int(60000 * p_val)\n",
    "idx_tr = list(range(60000))\n",
    "np.random.shuffle(idx_tr)\n",
    "idx_val = idx_tr[:n_val]\n",
    "idx_tr = idx_tr[n_val:]\n",
    "\n",
    "# Training CNN\n",
    "epochs = 30 # Change this number to ~30 for full training\n",
    "batch_size = 500\n",
    "t0 = time()\n",
    "# Set up Adam optimizer\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "# Set up dataloaders\n",
    "dl_tr = spectral_dataloader(X, y, idxs=idx_tr,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "dl_val = spectral_dataloader(X, y, idxs=idx_val,\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training!\n",
      " Epoch 1: 0.00s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28000/701270175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     acc_tr, loss_tr = run_epoch(epoch, cnn, dl_tr, cuda,\n\u001b[0;32m---> 21\u001b[0;31m         training=True, optimizer=optimizer)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Train acc: {:0.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/avellino/bacteria-ID/training.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(epoch, model, dataloader, cuda, training, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Fine-tune CNN for first fold\n",
    "best_val = 0\n",
    "no_improvement = 0\n",
    "max_no_improvement = 5\n",
    "print('Starting training!')\n",
    "for epoch in range(epochs):\n",
    "    print(' Epoch {}: {:0.2f}s'.format(epoch+1, time()-t0))\n",
    "    # Train\n",
    "    acc_tr, loss_tr = run_epoch(epoch, cnn, dl_tr, cuda,\n",
    "        training=True, optimizer=optimizer)\n",
    "    print('  Train acc: {:0.2f}'.format(acc_tr))\n",
    "    # Val\n",
    "    acc_val, loss_val = run_epoch(epoch, cnn, dl_val, cuda,\n",
    "        training=False, optimizer=optimizer)\n",
    "    print('  Val acc  : {:0.2f}'.format(acc_val))\n",
    "    # Check performance for early stopping\n",
    "    if acc_val > best_val or epoch == 0:\n",
    "        best_val = acc_val\n",
    "        no_improvement = 0\n",
    "        best_model = cnn\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    if no_improvement >= max_no_improvement:\n",
    "        print('Finished after {} epochs!'.format(epoch+1))\n",
    "        break\n",
    "\n",
    "torch.save(best_model.state_dict()\n",
    "           ,'pretrained_'+strftime('%y-%m-%d-%H-%M',localtime(t00))+'.ckpt')\n",
    "NA\n",
    "print('\\n completed in: {:0.2f}s'.format(time()-t00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training import get_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1000) (3000,)\n"
     ]
    }
   ],
   "source": [
    "X_test = './data/X_test.npy'\n",
    "y_test = './data/y_test.npy'\n",
    "X = np.load(X_test)\n",
    "y = np.load(y_test)\n",
    "print(X.shape, y.shape)\n",
    "dl_test = spectral_dataloader(X, y, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "982\n",
      "1475\n",
      "1969\n",
      "2464\n",
      "2954\n",
      "3449\n",
      "3944\n",
      "4434\n",
      "4930\n",
      "5424\n",
      "5921\n",
      "6412\n",
      "6908\n",
      "7403\n",
      "7895\n",
      "8388\n",
      "8881\n",
      "9374\n",
      "9861\n",
      "10355\n",
      "10850\n",
      "11343\n",
      "11837\n",
      "12328\n",
      "12819\n",
      "13316\n",
      "13811\n",
      "14298\n",
      "14791\n",
      "15283\n",
      "15776\n",
      "16267\n",
      "16763\n",
      "17254\n",
      "17747\n",
      "18240\n",
      "18735\n",
      "19225\n",
      "19721\n",
      "20213\n",
      "20705\n",
      "21197\n",
      "21689\n",
      "22182\n",
      "22677\n",
      "23176\n",
      "23669\n",
      "24160\n",
      "24655\n",
      "25148\n",
      "25641\n",
      "26132\n",
      "26625\n",
      "27117\n",
      "27611\n",
      "28105\n",
      "28597\n",
      "29090\n",
      "29581\n",
      "30076\n",
      "30568\n",
      "31060\n",
      "31554\n",
      "32047\n",
      "32543\n",
      "33032\n",
      "33526\n",
      "34018\n",
      "34510\n",
      "34999\n",
      "35490\n",
      "35983\n",
      "36473\n",
      "36964\n",
      "37455\n",
      "37943\n",
      "38436\n",
      "38926\n",
      "39420\n",
      "39912\n",
      "40407\n",
      "40896\n",
      "41393\n",
      "41887\n",
      "42382\n",
      "42876\n",
      "43364\n",
      "43854\n",
      "44346\n",
      "44841\n",
      "45329\n",
      "45822\n",
      "46314\n",
      "46810\n",
      "47304\n",
      "47797\n",
      "48289\n",
      "48785\n",
      "49280\n",
      "49772\n",
      "50261\n",
      "50756\n",
      "51250\n",
      "51740\n",
      "52235\n",
      "52728\n",
      "53224\n",
      "496\n",
      "985\n",
      "1476\n",
      "1968\n",
      "2461\n",
      "2953\n",
      "3448\n",
      "3946\n",
      "4438\n",
      "4928\n",
      "5425\n",
      "5923\n",
      "282\n",
      "567\n",
      "863\n",
      "1128\n",
      "1407\n",
      "1690\n",
      "train accuracy = 98.56296296296296%\n",
      "validation accuracy = 98.71666666666667%\n",
      "test accuracy = 56.333333333333336%\n"
     ]
    }
   ],
   "source": [
    "preds_tr, corr_tr = get_predictions(best_model,dl_tr,cuda)\n",
    "preds_val, corr_val = get_predictions(best_model,dl_val,cuda)\n",
    "preds_test, corr_test = get_predictions(best_model,dl_test,cuda)\n",
    "print(\"train accuracy = {}%\".format(corr_tr/54000*100))\n",
    "print(\"validation accuracy = {}%\".format(corr_val/6000*100))\n",
    "print(\"test accuracy = {}%\".format(corr_test/3000*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
